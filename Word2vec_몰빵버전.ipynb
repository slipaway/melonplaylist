{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2vec 몰빵버전",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/slipaway/melonplaylist/blob/%EC%84%B1%ED%99%98/Word2vec_%EB%AA%B0%EB%B9%B5%EB%B2%84%EC%A0%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0VCmEJX1SUK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b09a6326-cd3e-4ef9-be6d-5333a561b92a"
      },
      "source": [
        "!git clone https://github.com/kakao/khaiii.git\n",
        "!pip install cmake\n",
        "!mkdir build\n",
        "!cd build && cmake /content/khaiii\n",
        "!cd /content/build/ && make all\n",
        "!cd /content/build/ && make resource\n",
        "!cd /content/build && make install\n",
        "!cd /content/build && make package_python\n",
        "!pip install /content/build/package_python"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'khaiii' already exists and is not an empty directory.\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.6/dist-packages (3.12.0)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
            "mkdir: cannot create directory ‘build’: File exists\n",
            "-- The C compiler identification is GNU 7.5.0\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Check for working C compiler: /usr/bin/cc\n",
            "-- Check for working C compiler: /usr/bin/cc -- works\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Performing Test fma_compiles\n",
            "-- Performing Test fma_compiles - Success\n",
            "-- Performing Test fma_runs\n",
            "-- Performing Test fma_runs - Success\n",
            "-- [khaiii] fused multiply add option enabled\n",
            "-- [hunter] Calculating Toolchain-SHA1\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/cmake\", line 8, in <module>\n",
            "    sys.exit(cmake())\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/cmake/__init__.py\", line 34, in cmake\n",
            "    raise SystemExit(_program('cmake', sys.argv[1:]))\n",
            "\n",
            "[ 65%] Built target obj_khaiii\n",
            "[ 69%] Built target khaiii\n",
            "[ 76%] Built target bin_khaiii\n",
            "[100%] Built target test_khaiii\n",
            "Built target resource\n",
            "[ 65%] Built target obj_khaiii\n",
            "[ 69%] Built target khaiii\n",
            "[ 76%] Built target bin_khaiii\n",
            "[100%] Built target test_khaiii\n",
            "\u001b[36mInstall the project...\u001b[0m\n",
            "-- Install configuration: \"\"\n",
            "-- Up-to-date: /usr/local/include/khaiii\n",
            "-- Up-to-date: /usr/local/include/khaiii/khaiii_dev.h\n",
            "-- Up-to-date: /usr/local/include/khaiii/khaiii_api.h\n",
            "-- Up-to-date: /usr/local/include/khaiii/KhaiiiApi.hpp\n",
            "-- Up-to-date: /usr/local/share/khaiii\n",
            "-- Up-to-date: /usr/local/share/khaiii/embed.bin\n",
            "-- Up-to-date: /usr/local/share/khaiii/errpatch.tri\n",
            "-- Up-to-date: /usr/local/share/khaiii/restore.key\n",
            "-- Up-to-date: /usr/local/share/khaiii/conv.4.fil\n",
            "-- Up-to-date: /usr/local/share/khaiii/conv.3.fil\n",
            "-- Up-to-date: /usr/local/share/khaiii/errpatch.len\n",
            "-- Up-to-date: /usr/local/share/khaiii/hdn2tag.lin\n",
            "-- Up-to-date: /usr/local/share/khaiii/cnv2hdn.lin\n",
            "-- Up-to-date: /usr/local/share/khaiii/preanal.val\n",
            "-- Up-to-date: /usr/local/share/khaiii/preanal.tri\n",
            "-- Up-to-date: /usr/local/share/khaiii/conv.5.fil\n",
            "-- Up-to-date: /usr/local/share/khaiii/config.json\n",
            "-- Up-to-date: /usr/local/share/khaiii/conv.2.fil\n",
            "-- Up-to-date: /usr/local/share/khaiii/restore.one\n",
            "-- Up-to-date: /usr/local/share/khaiii/errpatch.val\n",
            "-- Up-to-date: /usr/local/share/khaiii/restore.val\n",
            "-- Up-to-date: /usr/local/lib/libkhaiii.so.0.4\n",
            "-- Up-to-date: /usr/local/lib/libkhaiii.so.0\n",
            "-- Up-to-date: /usr/local/lib/libkhaiii.so\n",
            "-- Up-to-date: /usr/local/bin/khaiii\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-373-8df09567ada3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd /content/build/ && make resource'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd /content/build && make install'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd /content/build && make package_python'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install /content/build/package_python'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    436\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   result = _run_command(\n\u001b[0;32m--> 438\u001b[0;31m       shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n\u001b[0m\u001b[1;32m    439\u001b[0m   \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     with temporary_clearer(), _display_stdin_widget(\n\u001b[0;32m--> 181\u001b[0;31m         delay_millis=500) as update_stdin_widget:\n\u001b[0m\u001b[1;32m    182\u001b[0m       \u001b[0;31m# TODO(b/115531839): Ensure that subprocesses are terminated upon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m       \u001b[0;31m# interrupt.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_display_stdin_widget\u001b[0;34m(delay_millis)\u001b[0m\n\u001b[1;32m    339\u001b[0m   \u001b[0mshell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ipython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m   \u001b[0mdisplay_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cell_display_stdin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'delayMillis'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdelay_millis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m   \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocking_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdisplay_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mecho_updater\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_echo_status\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0;31m# unique.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 438, in _run_callback\n",
            "    callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
            "    return self.dispatch_shell(stream, msg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
            "    handler(stream, idents, msg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 421, in execute_request\n",
            "    self._abort_queues()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 636, in _abort_queues\n",
            "    self._abort_queue(stream)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 654, in _abort_queue\n",
            "    self._publish_status('busy', parent=msg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 327, in _publish_status\n",
            "    ident=self._topic('status'),\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\", line 735, in send\n",
            "    if self.adapt_version:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/traitlets/traitlets.py\", line 556, in __get__\n",
            "    return self.get(obj, cls)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnT2cjWC1S8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05AzzSx_4fvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from datetime import timedelta, datetime\n",
        "import glob\n",
        "import os\n",
        "import re\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import re\n",
        "from collections import Counter\n",
        "from typing import *\n",
        "from khaiii import KhaiiiApi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USmPlJjA40sa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folder = '/content/gdrive/My Drive/melon'\n",
        "filelist = os.chdir(folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW4fKOGG43Vo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "genre_gn_all=pd.read_json('genre_gn_all.json', typ='series')\n",
        "train=pd.read_json('train.json')\n",
        "song_meta=pd.read_json('song_meta.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLXhdK7Q44i1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/slipaway/melonplaylist.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyZZC5FtPOil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "genre_gn_all.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfUIBSWhLD18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "genre_gn_all = pd.DataFrame(genre_gn_all, columns = ['gnr_name']).reset_index().rename(columns = {'index' : 'gnr_code'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQiTa394Lgr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gnr_code=genre_gn_all[genre_gn_all['gnr_code'].str[-2:]=='00']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFYahAWhMqEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#대장르 장르코드 리스트\n",
        "gnr_code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxjufnQ4NNmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#곡 아이디(id)와 대분류 장르코드 리스트(song_gn_gnr_basket) 추출\n",
        "\n",
        "song_gnr_map = song_meta.loc[:, ['id', 'song_gn_gnr_basket']]\n",
        "\n",
        "#unnest song_gn_gnr_basket\n",
        "song_gnr_map_unnest = np.dstack(\n",
        "    (\n",
        "        np.repeat(song_gnr_map.id.values, list(map(len, song_gnr_map.song_gn_gnr_basket))),\n",
        "        np.concatenate(song_gnr_map.song_gn_gnr_basket.values)\n",
        "    )\n",
        ")\n",
        "\n",
        "#unnested 데이터프레임 생성 : song_gnr_map\n",
        "\n",
        "song_gnr_map = pd.DataFrame(data = song_gnr_map_unnest[0], columns=song_gnr_map.columns)\n",
        "song_gnr_map['id']=song_gnr_map['id'].astype(str)\n",
        "song_gnr_map.rename(columns={'id' : 'song_id', 'song_gn_gnr_basket' : 'gnr_code'}, inplace=True)\n",
        "\n",
        "#unnest 객체 제거\n",
        "del song_gnr_map_unnest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMoJiQVSNE9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plylst_date = train[['updt_date', 'songs']]\n",
        "plylst_date_unnest = np.dstack(\n",
        "    (\n",
        "        np.repeat(plylst_date.updt_date.values, list(map(len, plylst_date.songs))), \n",
        "        np.concatenate(plylst_date.songs.values)\n",
        "    )\n",
        ")\n",
        "plylst_date = pd.DataFrame(data=plylst_date_unnest[0], columns = plylst_date.columns)\n",
        "\n",
        "del plylst_date_unnest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEXxTTSeOP-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plylst_date[\"updt_date\"] = plylst_date[\"updt_date\"].map(lambda x: x[:4] + x[5:7] + x[8:10])\n",
        "song_date = song_meta[[\"id\",\"issue_date\"]]\n",
        "plylst_song_date = pd.merge(plylst_date, song_date, left_on=\"songs\", right_on=\"id\", how='left')\n",
        "plylst_song_date[\"issue_date\"] = plylst_song_date[\"issue_date\"].astype(str)\n",
        "\n",
        "plylst_song_date[\"strange\"] = plylst_song_date[\"updt_date\"] < plylst_song_date[\"issue_date\"]\n",
        "strange_songs = plylst_song_date[plylst_song_date[\"strange\"] == True].drop('songs', axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8M-ezUihOnCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "strange_songs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-zxCom_QTwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "strange_songs=strange_songs.drop_duplicates(['id'])\n",
        "len(strange_songs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z23JH7LfRyq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "strange_songs_list=strange_songs['id'].values.astype(str)\n",
        "strange_song_gnr_map=song_gnr_map[song_gnr_map['song_id'].isin(strange_songs_list)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CoV2-zlTavC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "strange_cnt=strange_song_gnr_map.groupby('gnr_code').count()\n",
        "strange_cnt=pd.merge(strange_cnt, gnr_code, on='gnr_code')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enA_DwZxTiAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "strange_cnt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd9PHQxDTi66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "strange_songs=strange_songs.drop_duplicates(['id'])\n",
        "print(strange_songs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUi0tUpiV6qN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "strange_id=strange_songs.loc[:, 'id']\n",
        "strange_id\n",
        "strange_id_list=list(strange_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnbZbl_rXVza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_id=train.loc[:, 'id']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1ot2dxKYD__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "song_meta_id=song_meta.loc[:, 'id']\n",
        "print(song_meta_id.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgVtUq3KZcd9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "strange_songs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbmlODQwaTUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#플레이리스트 아이디(id)와 수록곡(songs) 추출\n",
        "plylst_song_map=train[['id', 'songs']]\n",
        "\n",
        "#unnest songs\n",
        "\n",
        "plylst_song_map_unnest=np.dstack(\n",
        "    (\n",
        "        np.repeat(plylst_song_map.id.values, list(map(len, plylst_song_map.songs))),\n",
        "        np.concatenate(plylst_song_map.songs.values)\n",
        "    )\n",
        ")\n",
        "\n",
        "#unnested 데이터프레임 생성 : plylst_song_map\n",
        "plylst_song_map=pd.DataFrame(data=plylst_song_map_unnest[0], columns=plylst_song_map.columns)\n",
        "plylst_song_map['id']=plylst_song_map['id'].astype(str)\n",
        "plylst_song_map['songs']=plylst_song_map['songs'].astype(str)\n",
        "\n",
        "del plylst_song_map_unnest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0iBSsTSce3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#플레이리스트에 수록된 곡의 총 개수(중복 포함)\n",
        "\n",
        "len(plylst_song_map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68aUJGZ1cnWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#플레이리스트에 strange 곡 제거한 후, 수록된 곡의 총 개수(중복 포함)\n",
        "\n",
        "plylst_song_map_remove=plylst_song_map[np.logical_not(plylst_song_map.songs.isin(strange_songs_list))]\n",
        "plylst_song_map_remove.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97aODOzJc-7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train set에 새로운 column : remove_songs 생성\n",
        "#remove_songs : strange 곡 제거한 후 다시 만든 플레이리스트\n",
        "\n",
        "plylst_song_group=plylst_song_map_remove.groupby('id')['songs'].apply(list).reset_index(name='remove_songs')\n",
        "train['id']=train['id'].astype(str)\n",
        "train_remove = pd.merge(train, plylst_song_group)\n",
        "\n",
        "train_remove.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNL3qMc349zf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def re_sub(series: pd.Series) -> pd.Series:\n",
        "  series = series.str.replace(pat=r'[ㄱ-ㅎ]', repl=r'', regex=True) #ㅋ 제거용\n",
        "  series = series.str.replace(pat=r'[^\\w\\s]', repl=r'', regex=True) #특수문자 제거용\n",
        "  series = series.str.replace(pat=r'[ ]{2,}', repl=r' ', regex=True) #공백 제거\n",
        "  series = series.str.replace(pat=r'[\\u3000]+', repl=r'', regex=True) #u3000제거\n",
        "  return series\n",
        "\n",
        "def flatten(list_of_list : List) -> List:\n",
        "  flatten = [j for i in list_of_list for j in i]\n",
        "  return flatten\n",
        "\n",
        "def get_token(title: str, tokenizer)-> List[Tuple]:\n",
        "\n",
        "  if len(title)==0 or title== ' ' : #제목이 공백인 경우 tokenizer 에러 발생\n",
        "    return []\n",
        "  \n",
        "  result = tokenizer.analyze(title)\n",
        "  result = [(morph.lex, morph.tag) for split in result for morph in split.morphs] # (형태소, 품사) 튜플의 리스트\n",
        "  return result\n",
        "\n",
        "def get_all_tags(df) -> List:\n",
        "  tag_list = df['tags'].values.tolist()\n",
        "  tag_list=flatten(tag_list)\n",
        "  return tag_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLrSZXG38Cdm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = KhaiiiApi()\n",
        "all_tag = get_all_tags(train)\n",
        "token_tag = [get_token(x, tokenizer) for x in all_tag] #태그를 형태소 분석"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTjnwdjx8LAO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_tag[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6Vq_Jim8lBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_itself=list(filter(lambda x: len(x)==1, token_tag)) # 태그 자체가 형태소여서 분리되지 않는 태그만 고름\n",
        "token_itself=flatten(token_itself)\n",
        "flatten_token=flatten(token_tag)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emHWOlHV89Zh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('%-23s'%'# of original tag is', f'{len(all_tag):8,}')\n",
        "print('%-23s'%'# of morpheme itself is', f'{len(token_itself):8,}')\n",
        "print('%-23s'%'# of total token is', f'{len(flatten_token):8,}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQJzX4Wi9UFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#counting part of speech (pos)\n",
        "pos=[x[1] for x in token_itself]\n",
        "pos_count=Counter(pos)\n",
        "popular_pos = pos_count.most_common()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZAGelxo9eAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tag 분류표\n",
        "objects=[x[0] for x in popular_pos]\n",
        "y_pos=np.arange(len(objects))\n",
        "performance=[x[1] for x in popular_pos]\n",
        "\n",
        "plt.barh(y_pos, performance, align='center', alpha=0.5)\n",
        "plt.yticks(y_pos, objects)\n",
        "plt.xlabel('Usage')\n",
        "plt.title('Part of Speech - Tags')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QFmzHrG9wZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#플레이리스트 제목 형태소 분석\n",
        "\n",
        "train['plylst_title']=re_sub(train['plylst_title'])\n",
        "train.loc[:, 'ply_token']=train['plylst_title'].map(lambda x: get_token(x, tokenizer))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePyNbzhL-AmR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "using_pos=['NNG', 'SL', 'NNP', 'MAG', 'SN'] #일반 명사, 외국어, 고유 명사, 일반 부사, 숫자\n",
        "train['ply_token']=train['ply_token'].map(lambda x: list(filter(lambda x: x[1] in using_pos, x)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNQd0v3L-x2b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique_tag=set(token_itself)\n",
        "unique_word=[x[0] for x in unique_tag]\n",
        "\n",
        "#train 데이터의 plylst title 형태소 분리"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm7R8N7v-4Fv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#정답 tag에 나온 형태소만 남겨두기\n",
        "train['ply_token']=train['ply_token'].map(lambda x: list(filter(lambda x: x[0] in unique_word, x)))\n",
        "train.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cv2B2-USU8rk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_eda = pd.merge(train, plylst_song_group)\n",
        "train_eda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q49PXYxGV6SH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wv_sent = train_eda[['ply_token', 'tags', 'remove_songs']]\n",
        "wv_sent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqLTKUoYKm4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Word2vec 이용을 위해 ply_token data를 전처리\n",
        "z = []\n",
        "y = []\n",
        "for i in range(len(wv_sent['ply_token'])):\n",
        "  z = []\n",
        "  for j in range(len(wv_sent['ply_token'][i])):\n",
        "    x = wv_sent['ply_token'][i][j]\n",
        "    x = list(x)\n",
        "    del x[1]\n",
        "    z.insert(j,\"\".join(x))\n",
        "  y.insert(i,z)\n",
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MiinRcRUYya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wv_sent['ply_token_new'] = y\n",
        "wv_sent = wv_sent[['ply_token_new', 'tags', 'remove_songs']]\n",
        "wv_sent # Word2vec 이용을 위해 필요한 data들만 모아둔 dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_AJQwFedBHi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_token_list = np.dstack(\n",
        "    (\n",
        "        np.concatenate(wv_sent.ply_token_new.values)\n",
        "    )\n",
        ")\n",
        "train_token_list = pd.DataFrame(train_token_list[0][0], columns = ['token'])\n",
        "train_token_list = list(train_token_list['token']) # train data에 존재하는 모든 플레이리스트 제목 형태소들의 list\n",
        "\n",
        "train_tag_list = np.dstack(\n",
        "    (\n",
        "        np.concatenate(wv_sent.tags.values)\n",
        "    )\n",
        ")\n",
        "train_tag_list = pd.DataFrame(train_tag_list[0][0], columns = ['tag'])\n",
        "train_tag_list = list(train_tag_list['tag']) # train data에 존재하는 모든 태그들의 list\n",
        "\n",
        "train_song_list = np.dstack(\n",
        "    (\n",
        "        np.concatenate(wv_sent.remove_songs.values)\n",
        "    )\n",
        ")\n",
        "train_song_list = pd.DataFrame(train_song_list[0][0], columns = ['song'])\n",
        "train_song_list = list(train_song_list['song']) # train data에 존재하는 노래들의 list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3Sqpod1bPhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_token_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsnYfX9JlrFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tag_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InqGK2vrltPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_songs_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoIWlUS9nmMG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Word2vec 사용을 위해 플레이리스트 별로 제목의 형태소와 태그, 단어를 한 문장으로 갖도록 전처리\n",
        "w = []\n",
        "for i in range(len(wv_sent)):\n",
        "  w.insert(i,wv_sent['ply_token_new'][i] + wv_sent['tags'][i] + wv_sent['remove_songs'][i])\n",
        "train_eda_fin = w\n",
        "train_eda_fin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkgPcGFLzl1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.test.utils import get_tmpfile\n",
        "from gensim.models.callbacks import CallbackAny2Vec\n",
        "class EpochSaver(CallbackAny2Vec):\n",
        "     '''Callback to save model after each epoch.'''\n",
        "\n",
        "     def __init__(self, path_prefix):\n",
        "         self.path_prefix = path_prefix\n",
        "         self.epoch = 0\n",
        "\n",
        "     def on_epoch_end(self, model):\n",
        "         output_path = get_tmpfile('{}_epoch{}.model'.format(self.path_prefix, self.epoch))\n",
        "         model.save(output_path)\n",
        "         self.epoch += 1\n",
        "\n",
        "class EpochLogger(CallbackAny2Vec):\n",
        "     def __init__(self):\n",
        "         self.epoch = 0\n",
        "\n",
        "     def on_epoch_begin(self, model):\n",
        "         print(\"Epoch #{} start\".format(self.epoch))\n",
        "\n",
        "     def on_epoch_end(self, model):\n",
        "         print(\"Epoch #{} end\".format(self.epoch))\n",
        "         self.epoch += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BJhF_VwXSiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "epoch_logger = EpochLogger()\n",
        "wv_model = Word2Vec(train_eda_fin, window = 10, min_count=7, workers=6, size = 400, iter=30, sg=1, callbacks=[epoch_logger])\n",
        "#min_count가 클수록, size가 작을수록 시간 단축인듯(정확도는...)\n",
        "#min_count = 7, size = 400, window = 10일 때 걸린 시간: 대략 반복당 2분\n",
        "#window size는 10개정도가 적당하다고 함(어느정도까지는 많을수록 좋음)\n",
        "#size는 10~100 정도가 적당하다고 함(차원이 클수록 오래걸리고, 차원이 높다고 항상 좋지는 않다고 함, 수십~수백 굿)\n",
        "#workers는 컴터 스펙에 따라 다른데 보통 4-6\n",
        "#min_count는 주로 10-100 사이인듯"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymhF6uMMtSAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wv_model.wv.most_similar(positive = ['아침', '눈', '크리스마스'],topn = 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ua1gn3sFrEY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "outputId": "f04679e1-7eee-4cd4-d36d-3ac51d752ad1"
      },
      "source": [
        "valid=pd.read_json('val.json')\n",
        "valid"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ed34f89842c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3YWtKJ5FCtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def re_sub(series: pd.Series) -> pd.Series:\n",
        "  series = series.str.replace(pat=r'[ㄱ-ㅎ]', repl=r'', regex=True) #ㅋ 제거용\n",
        "  series = series.str.replace(pat=r'[^\\w\\s]', repl=r'', regex=True) #특수문자 제거용\n",
        "  series = series.str.replace(pat=r'[ ]{2,}', repl=r' ', regex=True) #공백 제거\n",
        "  series = series.str.replace(pat=r'[\\u3000]+', repl=r'', regex=True) #u3000제거\n",
        "  return series\n",
        "\n",
        "def flatten(list_of_list : List) -> List:\n",
        "  flatten = [j for i in list_of_list for j in i]\n",
        "  return flatten\n",
        "\n",
        "def get_token(title: str, tokenizer)-> List[Tuple]:\n",
        "\n",
        "  if len(title)==0 or title== ' ' : #제목이 공백인 경우 tokenizer 에러 발생\n",
        "    return []\n",
        "  \n",
        "  result = tokenizer.analyze(title)\n",
        "  result = [(morph.lex, morph.tag) for split in result for morph in split.morphs] # (형태소, 품사) 튜플의 리스트\n",
        "  return result\n",
        "\n",
        "def get_all_tags(df) -> List:\n",
        "  tag_list = df['tags'].values.tolist()\n",
        "  tag_list=flatten(tag_list)\n",
        "  return tag_list\n",
        "\n",
        "tokenizer = KhaiiiApi()\n",
        "all_tag = get_all_tags(valid)\n",
        "token_tag = [get_token(x, tokenizer) for x in all_tag] #태그를 형태소 분석\n",
        "\n",
        "token_tag[:10]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0AKG2NzGv6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_itself=list(filter(lambda x: len(x)==1, token_tag)) # 태그 자체가 형태소여서 분리되지 않는 태그만 고름\n",
        "token_itself=flatten(token_itself)\n",
        "flatten_token=flatten(token_tag)\n",
        "print('%-23s'%'# of original tag is', f'{len(all_tag):8,}')\n",
        "print('%-23s'%'# of morpheme itself is', f'{len(token_itself):8,}')\n",
        "print('%-23s'%'# of total token is', f'{len(flatten_token):8,}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTDNFCuYG4vZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#counting part of speech (pos)\n",
        "pos=[x[1] for x in token_itself]\n",
        "pos_count=Counter(pos)\n",
        "popular_pos = pos_count.most_common()\n",
        "#tag 분류표\n",
        "objects=[x[0] for x in popular_pos]\n",
        "y_pos=np.arange(len(objects))\n",
        "performance=[x[1] for x in popular_pos]\n",
        "plt.barh(y_pos, performance, align='center', alpha=0.5)\n",
        "plt.yticks(y_pos, objects)\n",
        "plt.xlabel('Usage')\n",
        "plt.title('Part of Speech - Tags')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOerj0CmG4f6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#플레이리스트 제목 형태소 분석\n",
        "valid['plylst_title']=re_sub(valid['plylst_title'])\n",
        "valid.loc[:, 'ply_token']=valid['plylst_title'].map(lambda x: get_token(x, tokenizer))\n",
        "using_pos=['NNG', 'SL', 'NNP', 'MAG', 'SN'] #일반 명사, 외국어, 고유 명사, 일반 부사, 숫자\n",
        "valid['ply_token']=valid['ply_token'].map(lambda x: list(filter(lambda x: x[1] in using_pos, x)))\n",
        "unique_tag=set(token_itself)\n",
        "unique_word=[x[0] for x in unique_tag]\n",
        "#train 데이터의 plylst title 형태소 분리\n",
        "#정답 tag에 나온 형태소만 남겨두기\n",
        "valid['ply_token']=valid['ply_token'].map(lambda x: list(filter(lambda x: x[0] in unique_word, x)))\n",
        "valid.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3fKYcUjK_xH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plylst_date = valid[['updt_date', 'songs']]\n",
        "plylst_date_unnest = np.dstack(\n",
        "    (\n",
        "        np.repeat(plylst_date.updt_date.values, list(map(len, plylst_date.songs))), \n",
        "        np.concatenate(plylst_date.songs.values)\n",
        "    )\n",
        ")\n",
        "plylst_date = pd.DataFrame(data=plylst_date_unnest[0], columns = plylst_date.columns)\n",
        "\n",
        "del plylst_date_unnest\n",
        "plylst_date[\"updt_date\"] = plylst_date[\"updt_date\"].map(lambda x: x[:4] + x[5:7] + x[8:10])\n",
        "song_date = song_meta[[\"id\",\"issue_date\"]]\n",
        "plylst_song_date = pd.merge(plylst_date, song_date, left_on=\"songs\", right_on=\"id\", how='left')\n",
        "plylst_song_date[\"issue_date\"] = plylst_song_date[\"issue_date\"].astype(str)\n",
        "\n",
        "plylst_song_date[\"strange\"] = plylst_song_date[\"updt_date\"] < plylst_song_date[\"issue_date\"]\n",
        "strange_songs = plylst_song_date[plylst_song_date[\"strange\"] == True].drop('songs', axis=1)\n",
        "strange_songs=strange_songs.drop_duplicates(['id'])\n",
        "strange_songs_list=strange_songs['id'].values.astype(str)\n",
        "strange_song_gnr_map=song_gnr_map[song_gnr_map['song_id'].isin(strange_songs_list)] \n",
        "strange_cnt=strange_song_gnr_map.groupby('gnr_code').count()\n",
        "strange_cnt=pd.merge(strange_cnt, gnr_code, on='gnr_code')\n",
        "strange_id=strange_songs.loc[:, 'id']\n",
        "strange_id\n",
        "strange_id_list=list(strange_id)\n",
        "valid_id=valid.loc[:, 'id']\n",
        "song_meta_id=song_meta.loc[:, 'id']\n",
        "#플레이리스트 아이디(id)와 수록곡(songs) 추출\n",
        "plylst_song_map=valid[['id', 'songs']]\n",
        "\n",
        "#unnest songs\n",
        "\n",
        "plylst_song_map_unnest=np.dstack(\n",
        "    (\n",
        "        np.repeat(plylst_song_map.id.values, list(map(len, plylst_song_map.songs))),\n",
        "        np.concatenate(plylst_song_map.songs.values)\n",
        "    )\n",
        ")\n",
        "\n",
        "#unnested 데이터프레임 생성 : plylst_song_map\n",
        "plylst_song_map=pd.DataFrame(data=plylst_song_map_unnest[0], columns=plylst_song_map.columns)\n",
        "plylst_song_map['id']=plylst_song_map['id'].astype(str)\n",
        "plylst_song_map['songs']=plylst_song_map['songs'].astype(int).astype(str)\n",
        "\n",
        "del plylst_song_map_unnest\n",
        "#플레이리스트에 strange 곡 제거한 후, 수록된 곡의 총 개수(중복 포함)\n",
        "\n",
        "plylst_song_map_remove=plylst_song_map[np.logical_not(plylst_song_map.songs.isin(strange_songs_list))] \n",
        "plylst_song_map_remove.shape\n",
        "#valid set에 새로운 column : remove_songs 생성\n",
        "#remove_songs : strange 곡 제거한 후 다시 만든 플레이리스트\n",
        "\n",
        "plylst_song_group=plylst_song_map_remove.groupby('id')['songs'].apply(list).reset_index(name='remove_songs')\n",
        "valid['id']=valid['id'].astype(str)\n",
        "valid_remove = pd.merge(valid, plylst_song_group)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgYNKppCe3W6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_remove"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZpbrG6mUn8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = []\n",
        "for i in range(len(valid['songs'])):\n",
        "  x = len(valid['songs'][i])==0\n",
        "  y.insert(i,x)\n",
        "A = valid[y]\n",
        "A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg4FPt45Vfjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A['remove_songs'] = A['songs']\n",
        "A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkkwLydaNMxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_eda = pd.concat([valid_remove, A])\n",
        "valid_eda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJRoE63yMHLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_sent = valid_eda[['id', 'ply_token', 'tags', 'remove_songs']]\n",
        "val_sent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7mzLPvz_xpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_sent = val_sent.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCIGdUm2QXSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_sent = pd.DataFrame(val_sent)\n",
        "val_sent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqfzx-M-MKmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Word2vec 이용을 위해 ply_token data를 전처리\n",
        "z = []\n",
        "y = []\n",
        "for i in range(len(val_sent['ply_token'])):\n",
        "  z = []\n",
        "  if len(val_sent['ply_token'][i]) == 0:\n",
        "    x = val_sent['ply_token'][i]\n",
        "    z = x\n",
        "  else:\n",
        "    for j in range(len(val_sent['ply_token'][i])):\n",
        "     x = val_sent['ply_token'][i][j]\n",
        "     z.insert(j,x[0])\n",
        "  y.insert(i,z)\n",
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oujoQ_JsMM-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_sent['ply_token_new'] = y\n",
        "val_sent = val_sent[['ply_token_new', 'tags', 'remove_songs']]\n",
        "val_sent # Word2vec 이용을 위해 필요한 data들만 모아둔 dataframe\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3FOgByAMQPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Word2vec 사용을 위해 플레이리스트 별로 제목의 형태소와 태그, 단어를 한 문장으로 갖도록 전처리\n",
        "w = []\n",
        "for i in range(len(val_sent)):\n",
        "  w.insert(i,val_sent['ply_token_new'][i] + val_sent['tags'][i] + val_sent['remove_songs'][i])\n",
        "val_input = w\n",
        "val_input\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YfI92O4l2YA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(val_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQmnWUCMMUbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wv_model.wv.most_similar(positive = val_input[0],topn = 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgJ_2Tpyfhsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input: 플레이리스트 제목 or 곡 or 플레이리스트 제목&태그 or 곡&태그\n",
        "wv_model.wv.most_similar('',topn = #뽑힐 개수) #input이 여러 개면 ''대신 positive=['', '', ...]\n",
        "\n",
        "# 필요한 output: 곡 100개 & 태그 10개\n",
        "# x는 ['', '', ...]의 형식\n",
        "def result(x):\n",
        "  if wv_model.wv.most_similar(positive=x, topn = 100)[]\n",
        "\n",
        "\n",
        "while \n",
        "if "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}